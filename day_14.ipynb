{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 14: Extended Polymerization\n",
    "https://adventofcode.com/2021/day/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Apply 10 steps of pair insertion to the polymer template and find the most and least common elements in the result. What do you get if you take the quantity of the most common element and subtract the quantity of the least common element?\n",
    "\n",
    "\"This polymer grows quickly....\"  That is ominous.  Regardless, we will go for the simple solution and see what part 2 brings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import cache\n",
    "from typing import Tuple\n",
    "from advent_of_code import day_14\n",
    "from advent_of_code import utils\n",
    "\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file: str) -> Tuple[str, dict]:\n",
    "    \"\"\"\n",
    "    Parse input file into polymer template name (str)\n",
    "    and rules (dict) with the form k:v->element pair:element\n",
    "    \"\"\"\n",
    "    polymer: str = None\n",
    "    rules: dict = {}  # k:v -> element pair:element\n",
    "\n",
    "    with open(input_file) as f:\n",
    "        for line in f:\n",
    "            if line.rstrip() and not \"->\" in line:\n",
    "                polymer = line.rstrip()\n",
    "\n",
    "            elif line.rstrip() and \"->\" in line:\n",
    "                pair, insertion = line.rstrip().split(\" -> \")\n",
    "                rules[pair] = insertion\n",
    "\n",
    "    return polymer, rules\n",
    "\n",
    "def expand_pair(e1: str, e2: str, n: int, rules: dict) -> str:\n",
    "    \"\"\"Recurisve expansion of the pair down to n-steps. Return expanded pair (<str>).\"\"\"\n",
    "    insertion = rules.get(e1 + e2, \"\")\n",
    "    if n == 1:\n",
    "        return e1 + insertion + e2\n",
    "    else:\n",
    "        insertion = rules.get(e1 + e2, \"\")\n",
    "        return expand_pair(e1, insertion, n - 1, rules)[:-1] + expand_pair(\n",
    "            insertion, e2, n - 1, rules\n",
    "        )\n",
    "\n",
    "def expand(starting_polymer: str, rules: dict, steps: int = 1) -> str:\n",
    "    \"\"\"applies rules to starting polymer, and returns output.\"\"\"\n",
    "\n",
    "    resulting_polymer: str = \"\"\n",
    "\n",
    "    for e1, e2 in zip(starting_polymer, starting_polymer[1:]):\n",
    "        resulting_polymer = resulting_polymer + expand_pair(e1, e2, steps, rules)[:-1]\n",
    "\n",
    "    resulting_polymer = resulting_polymer + starting_polymer[-1]\n",
    "    return resulting_polymer\n",
    "\n",
    "def occurrance_count_check_counter(c: Counter) -> int:\n",
    "    \"\"\" \"\"\"\n",
    "    return c.most_common()[0][1] - c.most_common()[-1][1]\n",
    "\n",
    "def occurrance_count_check(polymer: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the quantity of the most common element minus the\n",
    "    least common element.\n",
    "    \"\"\"\n",
    "    c = Counter(polymer)\n",
    "    return occurrance_count_check_counter(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply test on page.\n",
    "test_input_file = utils.test_input_location(day=14)\n",
    "polymer, rules = read_input(test_input_file)\n",
    "\n",
    "assert expand(polymer, rules, 1) == \"NCNBCHB\"\n",
    "assert expand(polymer, rules, 2) == \"NBCCNBBBCBHCB\"\n",
    "assert expand(polymer, rules, 3) == \"NBBBCNCCNBBNBNBBCHBHHBCHB\"\n",
    "assert expand(polymer, rules, 4) == \"NBBNBNBBCCNBCNCCNBBNBBNBBBNBBNBBCBHCBHHNHCBBCBHCB\"\n",
    "assert occurrance_count_check(expand(polymer, rules, 10)) == 1588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2549"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = utils.input_location(day=14)\n",
    "polymer, rules = read_input(input_file)\n",
    "occurrance_count_check(expand(polymer, rules, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Apply 40 Steps.  ... Part 1 likely won't scale ... :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As assumed, this runs too long.\n",
    "Even attempting to cache the results to ```expand_pair``` does not yield enough speed up.\n",
    "\n",
    "```python\n",
    "test_input_file = utils.test_input_location(day=14)\n",
    "polymer, rules = read_input(test_input_file)\n",
    "assert occurrance_count_check(step(polymer, 40)) == 2188189693529\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def pair_count(pair: str, step: int, rules: day_14.FrozenDict) -> Counter:\n",
    "    \"\"\"\n",
    "    A recursive function to track pair expansions in a Counter object.\n",
    "    Returns counter\n",
    "    \"\"\"\n",
    "    if step == 0 or pair not in rules:\n",
    "        return Counter()\n",
    "    else:\n",
    "        c = Counter(rules.get(pair))\n",
    "        c.update(pair_count(pair[0] + rules.get(pair), step - 1, rules))\n",
    "        c.update(pair_count(rules.get(pair) + pair[1], step - 1, rules))\n",
    "        return c\n",
    "\n",
    "def expand_counts(starting_polymer: str, rules: dict, steps: int = 1) -> Counter:\n",
    "    \"\"\"\n",
    "    Wrapper around pair_count that calls for each starting pair combination\n",
    "    Returns counter object.\n",
    "    \"\"\"\n",
    "    # instead of a global variable, we use a hashable dictionary (custom class)\n",
    "    # this will enable us to benefit from the cache logic above.\n",
    "    frozen_rules = day_14.FrozenDict(rules)\n",
    "    c = Counter(starting_polymer)\n",
    "    for e1, e2 in zip(starting_polymer, starting_polymer[1:]):\n",
    "        c.update(pair_count(e1 + e2, steps, frozen_rules))\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate tests from part 1\n",
    "test_input_file = utils.test_input_location(day=14)\n",
    "polymer, rules = read_input(test_input_file)\n",
    "assert expand_counts(polymer, rules, 1)  == Counter(\"NCNBCHB\")\n",
    "assert expand_counts(polymer, rules, 2)  == Counter(\"NBCCNBBBCBHCB\")\n",
    "assert expand_counts(polymer, rules, 3)  == Counter(\"NBBBCNCCNBBNBNBBCHBHHBCHB\")\n",
    "assert expand_counts(polymer, rules, 4)  == Counter(\"NBBNBNBBCCNBCNCCNBBNBBNBBBNBBNBBCBHCBHHNHCBBCBHCB\")\n",
    "assert occurrance_count_check_counter(expand_counts(polymer, rules, 10)) == 1588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2549"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replicate part 1\n",
    "input_file = utils.input_location(day=14)\n",
    "polymer, rules = read_input(input_file)\n",
    "occurrance_count_check_counter(expand_counts(polymer, rules, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516901104210"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = utils.input_location(day=14)\n",
    "polymer, rules = read_input(input_file)\n",
    "occurrance_count_check_counter(expand_counts(polymer, rules, 40))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae981610c82baf8dde312b9cabe619eb6b77f5b8e197b22f2a09a689406db354"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
